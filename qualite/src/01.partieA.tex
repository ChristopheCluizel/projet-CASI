\section{A0}
  En tant qu'entreprise de statistiques, la compagnie Twitter Inc nous a demandé d'analyser les tweets d'internautes en temps réel afin de récupérer et d'illustrer le nombre de tweets par jour et par nationalité, ainsi que la taille des tweets en question. Cela leur permettra de mettre en place une infrastructure dynamique pour s'adapter à la charge selon l'heure de la journée. Ce projet a donc pour objectif d'améliorer un processus de développement en fournissant une solution d'analyse en temps réel.

\section{A1}
  \subsection{Mots-clés}
  \label{sub:Mots-clés}

    \begin{itemize}
      \item Tweet
      \item Spark streaming
      \item Parallélisation
      \item Visualisation
      \item Temps réel
      \item Profil utilisateur
      \item Data mining
      \item Big data
      \item Scalabilité
      \item Données
    \end{itemize}

  \subsection{Questions d'amorce}
  \label{sub:Questions d'amorce}

    Une grappe de serveurs (ou \textit{cluster}) est un regroupement de machines permettant de dépasser les capacités d'une machine. Il existe quatre cas d'utilisation pour une grappe de serveurs : \\

    \begin{description}
      \item[Mise à niveau de l'infrastructure] Ce système permet d'ajouter rapidement de nouveaux serveurs peu puissants et donc peu chers afin d'améliorer les performances. Avec l'utilisation d'une unique machine, l'amélioration peut devenir très coûteuse dans le cas de très grosses configurations.
      \item[Disponibilité de l'infrastructure] La multiplication des machines permet de disposer d'une infrastructure très stable. En effet, dans le meilleur des cas, il n'existe pas de machine maîtresse dans la grappe, il n'y a donc pas de \textit{single point of failure}.
      \item[Répartition de la charge] Il est possible avec une grappe de serveurs de diriger les requêtes de traitement vers le serveur le moins encombré. Si les machines sont situées dans des pays différents, il est également possible d'améliorer les performances (en particulier la latence) en dirigeant l'utilisateur vers la machine la plus proche.
      \item[Mutualisation des ressources] L'un des avantages les plus recherché dans l'utilisation d'une grappe de serveurs est la mutualisation des ressources. Il est en effet possible de créer des machines virtuelles profitant de toutes les ressources de la grappe. Il est nécessaire tout de même de faire attention au réseau entre les serveurs qui peut très vite devenir un goulot d'étranglement.
    \end{description} \bigskip

    Apache Hadoop est aujourd'hui le framework de calcul distribué le plus connu. En effet, tout un écosystème de traitement de données s'est développé autour : \\

    \begin{description}
      \item[HDFS] HDFS est le principal composant d'Hadoop, c'est celui qui permet de stocker les données de façon distribuées.
      \item[HBase] HBase est une base de données distribuée sur HDFS qui s'interface parfaitement avec Hadoop.
      \item[Hive] Hive est également un outil très utilisé qui permet d'effectuer des requêtes de type SQL sur des données distribuées.
      \item[Pig] Pig est un outil proche de Hive qui permet d'interroger des données dans un langage spécifique (le Pig Latin).
      \item[Drill] Drill permet d'interroger des données distribuées (HDFS, S3…) et des bases de données NoSQL via des requêtes de type SQL. Il est utile pour sa diversité.
      \item[Impala] Impala permet également de faire des requêtes de type SQL sur des données distribuées. Il est plus rapide que Hive.
      \item[Flume] Flume est un gestionnaire de queue distribués. Il permet de déplacer et d'aggréger de grandes quantités de données en temps réel.
      \item[Mahout] Mahout met à disposition des algorithmes distribués de \textit{machine learning}.
      \item[Giraph] Giraph est un outil d'analyse de graphes (notamment utilisé par Facebook pour l'analyse du réseau social).
      \item[Mesos] Mesos permet d'abstraire les ressources des machines (virtuelles ou physiques). Il fournit une API pour que les outils de l'écosystème Hadoop puissent accéder à ces ressources.
      \item[ZooKeeper] Enfin, ZooKeeper est un outil de gestion de configurations. L'écosystème d'Hadoop étant très diversifié, il est intéressant d'avoir un outil permettant de faire le lien entre tous les autres outils.
    \end{description} \bigskip
    Il existe de nombreux outils dans l'écosystème Hadoop et cette liste n'est pas exhaustive. De nombreux problèmes sont résolus par plusieurs d'entre eux car les solutions présentées sont souvent encore au stade de la recherche. Il est nécessaire de choisir le bon outil tout en sachant que des solutions plus performantes peuvent arriver très rapidement. \\

    Malgré la forte dominance d'Hadoop, le framework de calcul distribué Apache Spark est aujourd'hui plus rapide et profite d'une plus forte communauté. Apache Spark est également basé sur l'écosystème Hadoop et permet donc de profiter de tous les outils déjà développés. Certains modules natifs de Spark remplacent d'anciens outils comme pour Hive / Spark SQL ou Giraph / Spark GraphX.


\section{A2}
  \begin{description}
    \item[\href{http://spark.apache.org/streaming/}{Spark streaming}] Le site web d'Apache Spark contient de nombreuses informations et exemples concernant les algorithmes de Map / Reduce et de calculs distribués.
    \item[\href{https://dev.twitter.com}{Twitter Dev}] La documentation Twitter à destination des développeurs contient toutes les informations nécessaires à la récupération des tweets en temps réel (et en particulier la page \href{https://dev.twitter.com/streaming/overview}{sur l'API de Streaming})
    \item[\href{http://wiki.apache.org/hadoop}{Hadoop Wiki}] Le wiki d'Hadoop est également riche en informations sur les algorithmes de Map / Reduce. Il permet également d'accéder à de nombreuses autres documentations concernant des projets liés potentiellement utiles tels que \href{https://cwiki.apache.org/confluence/display/Hive/Home}{Hive} ou \href{https://cwiki.apache.org/confluence/display/PIG/Index}{Pig}.
  \end{description}

\section{A3}
  \begin{itemize}
    \item \href{http://www.amazon.fr/Real-Time-Analytics-Techniques-Visualize-Streaming/dp/1118837916/ref=sr_1_7?s=english-books&ie=UTF8&qid=1446301986&sr=1-7&keywords=streaming}{Real-Time Analytics: Techniques to Analyze and Visualize Streaming Data}. Chapitre 1: ``Introduction to Streaming data''
    \item \href{http://www.amazon.com/Learning-Spark-Lightning-Fast-Data-Analysis/dp/1449358624/ref=sr_1_1?ie=UTF8&qid=1446301706&sr=8-1&keywords=apache+spark}{Learning Spark: Lightning-Fast Big Data Analysis}. Chapitre 10: ``Spark Streaming''
    \item \href{http://www.amazon.fr/Learning-Real-time-Processing-Spark-Streaming-ebook/dp/B015Q7I3NM/ref=sr_1_2?s=english-books&ie=UTF8&qid=1446301986&sr=1-2&keywords=streaming}{Learning Real-time Processing with Spark Streaming}. Chapitre 2: ``Architecture and Components of Spark and Spark Streaming''
  \end{itemize}

\section{A4}
  \subsection{Apache}

    La fondation Apache est une organisation à but non lucratif dont l'objectif est de développer des logiciels open-source. Le logiciel le plus connu est sans aucun doute le serveur web Apache. Tout projet open-source sous licence Apache 2 peut devenir un projet de la fondation Apache après une période d'incubation. \\

    De nombreux logiciels de traitement de données sont soutenus par la fondation dont Apache Hadoop, Apache Spark, Apache Lucene ou encore Apache Kafka. Les frameworks de calcul Hadoop et Spark sont aujourd'hui les plus utilisés dans le monde de l'analyse de masse de données. Apache Lucene est le moteur d'indexation utilisé par tous les grands projets open-source comme par exemple les moteurs de recherche Apache Solr et ElasticSearch. Apache Kafka est un système de queue de messages utilisé par plusieurs grandes entreprises comme Linkedin, Netflix ou Spotify.

  \subsection{Google}

    Google est actuellement le plus grand moteur de recherche du monde. Son business model est basé sur la publicité et les données utilisateurs. Cette particularité explique que Google soit la première entreprise à avoir rencontré des problèmes liés aux masses de données. La première contribution de Google a été faite sur l'analyse de masses de données de manière distribuée avec le paradigme de MapReduce. Ce type de programmation est expliqué dans un article de recherche de 2004 \href{https://www.usenix.org/legacy/publications/library/proceedings/osdi04/tech/full_papers/dean/dean_html/index.html}{MapReduce: Simplified Data Processing on Large Clusters}.\\

    Deux ans plus tard, Google va contribuer à nouveau sur les problématiques de masses de données en dévoilant BigTable, un système de stockage de données distribué à nouveau dans un article de recherche \href{http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/bigtable-osdi06.pdf}{Bigtable: A Distributed Storage System for Structured Data}. Ces deux articles vont être la base des frameworks d'analyse de données Hadoop et Spark qui exploite le paradigme MapReduce. Les données sont stockées au format HDFS, un format dérivé de la solution BigTable propriétaire de Google.

  \subsection{Amazon}
    Amazon.com est une société de commerce électronique. En 2002, elle lance un nouveau produit appelé Amazon Web Services (AWS) permettant d’accéder à des fonctions latentes sur son site web. Ce nouveau produit va être un regroupement de services très utiles pour les entreprises intéressées dans le domaine de la masse de données. Tout d'abord avec Amazon Simple Storage Service (Amazon S3), un service de stockage de fichier volumineux. Il est possible de stocker très facilement des teraoctects de données dans S3 et de les analyser avec Hadoop ou Spark. Puis avec un système de serveurs virtualisé à la demande: Amazon Elastic Compute Cloud (Amazon EC2). \\

    Ce service permet de déployer des applications très facilement et de faire évoluer la puissance de calcul nécessaire en fonction du besoin en quelques clics. En 2013, Amazon dévoile Redshift, une base de données de type SQL permettant de traiter des masses de données efficacement. AWS permet aussi avec Amazon Elastic MapReduce (Amazon EMR) de traiter ses données via un cluster Hadoop ou Spark. Les prix très attractifs d'AWS peuvent expliquer l'engouement actuel pour ces technologies car de nombreuses entreprises ont pu se lancer dans des analyses sans investir des sommes astronomiques dans les machines et la configuration des clusters.

  \subsection{Smile}
    \href{http://www.smile.fr/}{Smile} est le leader français de l'intégration de logiciels open-source. Il propose des livres blancs disponibles gratuitement dans de nombreux domaines. Pour notre projet, nous avons choisi le livre blanc \href{http://www.smile.fr/Livres-blancs}{``Search Engines and E-merchandising: The State of the Art''} afin d'illustrer les possibilités des moteurs de recherche. Cet état de l'art ne correspond pas exactement à notre domaine d'application, mais expose plusieurs alternatives que nous aurions pu utiliser pour traiter nos tweet.

\section{A5}
  \begin{enumerate}
    \item Time behaviour
    \item Resource utilization
    \item Installability
  \end{enumerate}

\section{A6}
  \begin{enumerate}
    \item Time behaviour
      \begin{itemize}
        \item Response time (Internal)
        \item Task time
        \item Response time for display on Kibana - unit: second.
      \end{itemize} \bigskip

      Les \emph{response time} et \emph{task time} seront mesurés à l'aide d'un ``tic-toc'', c'est-à-dire la différence entre le timestamp avant et après l'exécution d'une fonction, d'un groupe de fonctions ou d'une tâche. \\

    \item Resource utilization
      \begin{itemize}
        \item Transmission capacity
        \item Number of memory related errors
        \item CPU usage - unit: percentage from total.
      \end{itemize} \bigskip

    \item Installability
      \begin{itemize}
        \item Number of installation steps
        \item Number of set-up operations
        \item Number of architectures which can be used as workers for Spark computation - unit: number
      \end{itemize} \bigskip
  \end{enumerate}

\section{A7}
  Notre projet s'articule autour d'un certain nombre de patterns d'intégration dans le cadre de l'``Entreprise Application Integration'' (EAI), car nous sommes amenés à faire communiquer des applications qui n'ont pas été conçues à la base pour communiquer ensemble ; à savoir l'application de streaming de Twitter et notre programme d'analyse de tweets. \\

  Afin de garantir une rapidité de traitement, le type d'intégration utilisé peut être le ``Distributed Business processes'' (BPM) pour ainsi effectuer les traitements sur plusieurs machines de façon indépendante. C'est par exemple le cas avec Spark qui permet d'effectuer les calculs sur un cluster et donc sur un ensemble de machines à l'aide de ce que l'on appelle le ``map-reduce''. Le ``map'' correspond à la distribution des calculs sur chaque machine et le fait que chaque machine peut effectuer ses calculs indépendamment. Le ``reduce'' correspond au regroupement sur une seule machine des différents résultats calculés sur l'ensemble des machines. \\

  Pour notre projet, nous avons relevé plusieurs patterns qui peuvent s'appliquer à notre cas d'analyse de tweets, regroupés dans différentes catégories d'``Entreprise Integration Patterns'' (EIP).

  \subsection{Messaging Systems}
    \paragraph{Message Channel} Notre projet doit faire communiquer 2 applications et donc il est nécessaire d'avoir un système permettant de communiquer entre elles.

    \paragraph{Message} À travers ce système de communication, de nombreuses informations vont circuler sous forme de messages.

    \paragraph{Message translator} Une fois le message (informations brutes de tweets) arrivé dans notre application, celui-ci va être traité et ressortir sous la forme d'un message d'un autre format, à savoir des statistiques sur les informations entrantes.

    \paragraph{Message Endpoint} Ce pattern permet de gérer le point de sortie pour l'application Twitter et le point d'entrée pour notre application de traitement.

  \subsection{Message Routing}
    \paragraph{Aggregator} L'ensemble des messages vont être traités et agrégés afin de réaliser des statistiques sur la totalité des tweets reçus.

  \subsection{Message Endpoints}
    \paragraph{Polling Consumer} Afin de ne pas engorger notre application par la masse de messages reçus, il faut mettre en place un système pour réguler la consommation de ces messages. Des précisions seront apportées dans la partie~\ref{sec:B1}.

  \subsection{Message Transformation}
    \paragraph{Content Filter} Un tweet contient un grand nombre d'informations qui ne sont pas utiles à notre analyse. Il faut donc prévoir un moyen de filtrer l'information reçue par notre application.
