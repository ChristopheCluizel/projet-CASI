\section{A0}
  En tant qu'entreprise de statistiques, la compagnie Twitter Inc nous a demandé d'analyser les tweets d'internautes en temps réel afin de récupérer et d'illustrer le nombre de tweets par jour et par nationalité, ainsi que la taille des tweets en question. Cela leur permettra de mettre en place une infrastructure dynamique pour s'adapter à la charge selon l'heure de la journée. Ce projet a donc pour objectif d'améliorer un processus de développement en fournissant une solution d'analyse en temps réel.

\section{A1}
  \begin{itemize}
    \item Tweet
    \item Spark streaming
    \item Parallélisation
    \item Visualisation
    \item Temps réel
    \item Profil utilisateur
    \item Data mining
    \item Big data
    \item Scalabilité
    \item Données
  \end{itemize}

\section{A2}
  \begin{itemize}
    \item [Spark streaming](http://spark.apache.org/streaming/)
    \item [ElasticSearch](https://www.elastic.co/products/elasticsearch)
    \item [Kibana](https://www.elastic.co/products/kibana)
  \end{itemize}

\section{A3}
  % * [Real-Time Analytics: Techniques to Analyze and Visualize Streaming Data](http://www.amazon.fr/Real-Time-Analytics-Techniques-Visualize-Streaming/dp/1118837916/ref=sr_1_7?s=english-books&ie=UTF8&qid=1446301986&sr=1-7&keywords=streaming). Chapitre 1 : « Introduction to Streaming data »
  % * [Learning Spark: Lightning-Fast Big Data Analysis](http://www.amazon.com/Learning-Spark-Lightning-Fast-Data-Analysis/dp/1449358624/ref=sr_1_1?ie=UTF8&qid=1446301706&sr=8-1&keywords=apache+spark). Chapitre 10 : « Spark Streaming »
  % * [Learning Real-time Processing with Spark Streaming](http://www.amazon.fr/Learning-Real-time-Processing-Spark-Streaming-ebook/dp/B015Q7I3NM/ref=sr_1_2?s=english-books&ie=UTF8&qid=1446301986&sr=1-2&keywords=streaming). Chapitre 2 : « Architecture and Components of Spark and Spark Streaming »

\section{A4}
  Apache

  % La fondation Apache est une organisation à but non lucratif dont l'objectif est de développer des logiciels open-source. Le logiciel le plus connu est sans aucun doute le serveur web Apache. Tout projet open-source sous licence Apache 2 peut devenir un projet de la fondation Apache après une période d'incubation.
  % De nombreux logiciels de traitement de données sont soutenus par la fondation dont Apache Hadoop, Apache Spark, Apache Lucene ou encore Apache Kafka. Les frameworks de calcul Hadoop et Spark sont aujourd'hui les plus utilisés dans le monde de l'analyse de masse de données. Apache Lucene est le moteur d'indexation utilisé par tous les grands projets open-source comme par exemple les moteurs de recherche Apache Solr et ElasticSearch. Apache Kafka est un système de queue de messages utilisé par plusieurs grandes entreprises comme Linkedin, Netflix ou Spotify.

  Google

  % Google est actuellement le plus grand moteur de recherche du monde. Son business model est basé sur la publicité et les données utilisateurs. Cette particularité explique que Google soit la première entreprise à avoir rencontré des problèmes liés aux masses de données. La première contribution de Google a été faite sur l'analyse de masses de données de manière distribuée avec le paradigme de MapReduce. Ce type de programmation est expliqué dans un article de recherche de 2004 [MapReduce: Simplified Data Processing on Large Clusters](https://www.usenix.org/legacy/publications/library/proceedings/osdi04/tech/full_papers/dean/dean_html/index.html). Deux ans plus tard, Google va contribuer à nouveau sur les problèmatiques de masses de données en dévoilant BigTable, un système de stockage de données distribué à nouveau dans un article de recherche [Bigtable: A Distributed Storage System for Structured Data](http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/bigtable-osdi06.pdf). Ces deux articles vont être la base des frameworks d'analyse de données Hadoop et Spark qui exploite le paradigme MapReduce. Les données sont stockées au format HDFS, un format dérivé de la solution BigTable propriétaire de Google.

  Amazon

  % Amazon.com est une société de commerce électronique. En 2002, elle lance un nouveau produit appelé Amazon Web Services (AWS) permettant d’accéder à des fonctions latentes sur son site web. Ce nouveau produit va être un regroupement de services très utiles pour les entreprises intéressées dans le domaine de la masse de données. Tout d'abord avec Amazon Simple Storage Service (Amazon S3), un service de stockage de fichier volumineux. Il est possible de stocker très facilement des teraoctects de données dans S3 et de les analyser avec Hadoop ou Spark. Puis avec un système de serveurs virtualisé à la demande : Amazon Elastic Compute Cloud (Amazon EC2). Ce service permet de déployer des applications très facilement et de faire évoluer la puissance de calcul nécessaire en fonction du besoin en quelques clics. En 2013, Amazon dévoile Redshift, une base de données de type SQL permettant de traiter des masses de données efficacement. AWS permet aussi avec Amazon Elastic MapReduce (Amazon EMR) de traiter ses données via un cluster Hadoop ou Spark. Les prix très attractifs d'AWS peuvent expliquer l'engouement actuel pour ces technologies car de nombreuses entreprises ont pu se lancer dans des analyses sans investir des sommes astronomiques dans les machines et la configuration des clusters.

  Smile

  % [Smile](http://www.smile.fr/) est le leader français de l'intégration de logiciels open-source. Il propose des livres blancs disponibles gratuitement dans de nombreux domaines. Pour notre projet, nous avons choisi le livre blanc ["Search Engines and E-merchandising: The State of the Art"](http://www.smile.fr/Livres-blancs) afin d'illustrer les possibilités des moteurs de recherche. Cet état de l'art ne correspond pas exactement à notre domaine d'application, mais expose plusieurs alternatives que nous aurions pu utiliser pour traiter nos tweet.

\section{A5}
  * Time behaviour
  * Resource utilization
  * Instability

\section{A6}
  * Time behaviour
    + Response time (Internal)
    + Task time
    + Response time for display on Kibana - unit: second.

  * Resource utilization
      + Transmission capacity
      + Number of memory related errors
      + CPU usage - unit: percentage from total.

  * Instability
      + Number of installation steps
      + Number of set-up operations
      + Number of architectures which can be used as workers for Spark computation - unit: number

\section{A7}
